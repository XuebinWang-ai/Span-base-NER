[Data]
bert_model = '/data3/xbwang/syntax_aware_seqtag-nogaz/bert-base-chinese/'
bert_wwm_model = '/data3/xbwang/syntax_aware_seqtag-nogaz/bert-wwm/'

[Network]
n_embed = 100
n_char_embed = 50

n_feat_embed = 768
n_bert_layers = 4

embed_dropout = .1
n_mlp_span = 300
mlp_dropout = .1

[Optimizer]
lr = 2e-5
mu = .9
nu = .9
epsilon = 1e-12
clip = 5.0
decay = .75
decay_epochs = 50
update_steps = 1
warmup = 0.1

[Run]
batch_size = 3000
epochs = 20
patience = 10
min_freq = 2
